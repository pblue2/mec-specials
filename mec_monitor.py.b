import requests
from bs4 import BeautifulSoup
import os
import json
import hashlib
import time
from urllib.parse import urljoin

# ================= é…ç½®åŒºåŸŸ =================
TARGET_URL = "https://www.mec.ca/en/p/featured"

# æ•°æ®æŒä¹…åŒ–ç›®å½• (å®¹å™¨å†…è·¯å¾„ï¼Œæ˜ å°„åˆ°å®¿ä¸»æœº /mnt/mec-special)
# å¿…é¡»ä¸ Dockerfile å’Œ K8s YAML ä¸­çš„æŒ‚è½½è·¯å¾„ä¸€è‡´
DATA_DIR = "/mnt/mec-special"
IMAGES_DIR = os.path.join(DATA_DIR, "images")
DB_FILE = os.path.join(DATA_DIR, "promotions_db.json")

# Bark é€šçŸ¥é…ç½®
BARK_URLS = [
    "https://api.day.app/SLqpVbfocFSrHMFVK7Ft5k/",
    "https://api.day.app/ScqA3Kv7Ed9XV9E7tLdFEN/"
]
BARK_ICON = "https://www.mec.ca/favicons/apple-touch-icon.png"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
}

# ================= æ ¸å¿ƒä»£ç  =================

def ensure_dirs():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    if not os.path.exists(IMAGES_DIR):
        try:
            os.makedirs(IMAGES_DIR, exist_ok=True)
            print(f"âœ… ç›®å½•å·²åˆ›å»º: {IMAGES_DIR}")
        except Exception as e:
            print(f"âŒ ç›®å½•åˆ›å»ºå¤±è´¥: {e}")

def load_db():
    """è¯»å–å†å²è®°å½•"""
    if os.path.exists(DB_FILE):
        try:
            with open(DB_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_db(data):
    """ä¿å­˜è®°å½•åˆ° JSON"""
    try:
        with open(DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")

def download_image_local(img_url, file_name):
    """ä¸‹è½½å›¾ç‰‡ä¿å­˜åˆ°æœ¬åœ°ç¡¬ç›˜"""
    save_path = os.path.join(IMAGES_DIR, file_name)
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
    if os.path.exists(save_path):
        return save_path
    
    try:
        resp = requests.get(img_url, headers=HEADERS, timeout=10)
        if resp.status_code == 200:
            with open(save_path, 'wb') as f:
                f.write(resp.content)
            return save_path
    except Exception as e:
        print(f"âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥ ({file_name}): {e}")
    return None

def send_bark(title, content, remote_img_url):
    """å‘é€ Bark é€šçŸ¥"""
    print(f"ğŸ”” å‘é€é€šçŸ¥: {title}")
    params = {
        "title": f"MEC æ–°ä¿ƒé”€: {title}",
        "body": content,
        "icon": BARK_ICON,
        "image": remote_img_url, # ä½¿ç”¨è¿œç¨‹ URL è®© Bark å®¢æˆ·ç«¯ç›´æ¥åŠ è½½ï¼Œé€Ÿåº¦æœ€å¿«
        "group": "MECç›‘æ§",
        "copy": content
    }
    
    for base_url in BARK_URLS:
        try:
            url = base_url if base_url.endswith('/') else base_url + "/"
            requests.post(url, data=params, timeout=5)
        except Exception as e:
            print(f"âŒ Bark å‘é€å¤±è´¥ {base_url[:15]}...: {e}")

def extract_promotions(html):
    """è§£æ HTML ç»“æ„"""
    soup = BeautifulSoup(html, 'html.parser')
    promos = []
    
    # æŸ¥æ‰¾ article æ ‡ç­¾
    articles = soup.find_all('article')
    
    # å¤‡ç”¨æ–¹æ¡ˆï¼šå¦‚æœæ‰¾ä¸åˆ° articleï¼ŒæŸ¥æ‰¾ main é‡Œçš„å†…å®¹
    if not articles:
        main_content = soup.find('main', id='main-content')
        if main_content:
            articles = main_content.find_all('article')

    for art in articles:
        # æå–æ ‡é¢˜
        h4 = art.find('h4')
        if not h4: continue
        title = h4.get_text(strip=True)
        
        # ç”Ÿæˆ ID
        pid = hashlib.md5(title.encode('utf-8')).hexdigest()
        
        # æå–æè¿°å’Œä¼˜æƒ ç 
        details_text = ""
        promo_code = "æ— ä¼˜æƒ ç "
        
        details_div = art.find('div', class_=lambda x: x and 'RichTextContainer' in x)
        if details_div:
            # è·å–æ‰€æœ‰æ®µè½æ–‡æœ¬
            paragraphs = [p.get_text(strip=True) for p in details_div.find_all('p')]
            details_text = "\n".join(paragraphs)
            
            # ç®€å•çš„ä¼˜æƒ ç æå–é€»è¾‘
            for p_text in paragraphs:
                if "Promo Code" in p_text or "Code:" in p_text:
                    parts = p_text.split(":")
                    if len(parts) > 1:
                        promo_code = parts[1].strip()

        # æå–å›¾ç‰‡ URL
        img_url = ""
        img_tag = art.find('img')
        if img_tag:
            src = img_tag.get('src', '') or img_tag.get('srcset', '').split(' ')[0]
            if src.startswith('/'):
                img_url = urljoin(TARGET_URL, src)
            else:
                img_url = src

        promos.append({
            "id": pid,
            "title": title,
            "details": details_text,
            "code": promo_code,
            "img_url": img_url
        })
        
    return promos

def main():
    print(f"ğŸš€ MEC ç›‘æ§å¯åŠ¨æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    ensure_dirs()
    
    # 1. è·å–ç½‘é¡µ
    try:
        resp = requests.get(TARGET_URL, headers=HEADERS, timeout=20)
        resp.raise_for_status()
    except Exception as e:
        print(f"âŒ ç½‘ç»œé”™è¯¯: {e}")
        return

    # 2. è§£æ
    current_promos = extract_promotions(resp.text)
    print(f"ğŸ” å‘ç° {len(current_promos)} ä¸ªä¿ƒé”€æ´»åŠ¨")
    
    # 3. åŠ è½½å†å²
    db = load_db()
    is_first_run = len(db) == 0
    
    if is_first_run:
        print("ğŸ”° é¦–æ¬¡è¿è¡Œæ£€æµ‹ï¼šæ­£åœ¨å»ºç«‹åŸºå‡†æ•°æ®åº“ï¼ˆä¸å‘é€é€šçŸ¥ï¼‰ã€‚")

    new_db = db.copy()
    
    # 4. å¯¹æ¯”é€»è¾‘
    for p in current_promos:
        pid = p['id']
        
        # æ— è®ºæ–°æ—§ï¼Œéƒ½æŠŠå›¾ç‰‡ä¿å­˜ä¸€ä»½åˆ°æœ¬åœ°ç¡¬ç›˜
        local_filename = f"{pid}.jpg"
        download_image_local(p['img_url'], local_filename)
        
        if pid not in db:
            print(f"ğŸ†• å‘ç°æ–°æ´»åŠ¨: {p['title']}")
            
            new_db[pid] = {
                "title": p['title'],
                "code": p['code'],
                "img_file": local_filename,
                "first_seen": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # éé¦–æ¬¡è¿è¡Œæ‰å‘é€é€šçŸ¥
            if not is_first_run:
                # æˆªå–è¯¦æƒ…é˜²æ­¢è¿‡é•¿
                short_details = p['details'][:100] + "..." if len(p['details']) > 100 else p['details']
                msg_body = f"Code: {p['code']}\n{short_details}"
                send_bark(p['title'], msg_body, p['img_url'])
        else:
            print(f"ğŸ’¤ å·²å­˜åœ¨: {p['title'][:20]}...")

    # 5. ä¿å­˜
    save_db(new_db)
    print(f"âœ… æ‰§è¡Œå®Œæ¯•ã€‚æ•°æ®å·²ä¿å­˜è‡³ {DATA_DIR}")

if __name__ == "__main__":
    main()
